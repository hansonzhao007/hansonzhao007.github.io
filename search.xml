<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[LevelDb 详解]]></title>
    <url>%2F2017%2F08%2F23%2FLevelDb%20Introduction%2F</url>
    <content type="text"><![CDATA[说起LevelDb也许您不清楚，但是如果作为IT工程师，不知道下面两位大神级别的工程师，那您的领导估计会Hold不住了：Jeff Dean和Sanjay Ghemawat。这两位是Google公司重量级的工程师，为数甚少的Google Fellow之二。 Jeff Dean其人：http://research.google.com/people/jeff/index.html，Google大规模分布式平台Bigtable和MapReduce主要设计和实现者。 Sanjay Ghemawat其人：http://research.google.com/people/sanjay/index.html，Google大规模分布式平台GFS，Bigtable和MapReduce主要设计和实现工程师。 LevelDb就是这两位大神级别的工程师发起的开源项目，简而言之，LevelDb是能够处理十亿级别规模Key-Value型数据持久性存储的C++ 程序库。正像上面介绍的，这二位是Bigtable的设计和实现者，如果了解Bigtable的话，应该知道在这个影响深远的分布式存储系统中有两个核心的部分：Master Server和Tablet Server。其中Master Server做一些管理数据的存储以及分布式调度工作，实际的分布式数据存储以及读写操作是由Tablet Server完成的，而LevelDb则可以理解为一个简化版的Tablet Server。 LevelDb有如下一些特点： 首先，LevelDb是一个持久化存储的KV系统，和Redis这种内存型的KV系统不同，LevelDb不会像Redis一样狂吃内存，而是将大部分数据存储到磁盘上。 其次，LevleDb在存储数据时，是根据记录的key值有序存储的，就是说相邻的key值在存储文件中是依次顺序存储的，而应用可以自定义key大小比较函数，LevleDb会按照用户定义的比较函数依序存储这些记录。 再次，像大多数KV系统一样，LevelDb的操作接口很简单，基本操作包括写记录，读记录以及删除记录。也支持针对多条操作的原子批量操作。 另外，LevelDb支持数据快照（snapshot）功能，使得读取操作不受写操作影响，可以在读操作过程中始终看到一致的数据。 除此外，LevelDb还支持数据压缩等操作，这对于减小存储空间以及增快IO效率都有直接的帮助。 LevelDb性能非常突出，官方网站报道其随机写性能达到40万条记录每秒，而随机读性能达到6万条记录每秒。总体来说，LevelDb的写操作要大大快于读操作，而顺序读写操作则大大快于随机读写操作。至于为何是这样，看了我们后续推出的LevelDb日知录，估计您会了解其内在原因。 整体架构LevelDb本质上是一套存储系统以及在这套存储系统上提供的一些操作接口。为了便于理解整个系统及其处理流程，我们可以从两个不同的角度来看待LevleDb：静态角度和动态角度。 从静态角度，可以假想整个系统正在运行过程中（不断插入删除读取数据），此时我们给LevelDb照相，从照片可以看到之前系统的数据在内存和磁盘中是如何分布的，处于什么状态等；从动态的角度，主要是了解系统是如何写入一条记录，读出一条记录，删除一条记录的，同时也包括除了这些接口操作外的内部操作比如compaction，系统运行时崩溃后如何恢复系统等等方面。 本节所讲的整体架构主要从静态角度来描述，之后接下来的几节内容会详述静态结构涉及到的文件或者内存数据结构，LevelDb日知录后半部分主要介绍动态视角下的LevelDb，就是说整个系统是怎么运转起来的。 LevelDb作为存储系统，数据记录的存储介质包括内存以及磁盘文件，如果像上面说的，当LevelDb运行了一段时间，此时我们给LevelDb进行透视拍照，那么您会看到如下一番景象： 从图中可以看出，构成LevelDb静态结构的包括六个主要部分：内存中的MemTable和Immutable MemTable以及磁盘上的几种主要文件：Current文件，Manifest文件，log文件以及SSTable文件。当然，LevelDb除了这六个主要部分还有一些辅助的文件，但是以上六个文件和数据结构是LevelDb的主体构成元素。 LevelDb的Log文件和Memtable与Bigtable论文中介绍的是一致的，当应用写入一条Key:Value记录的时候，LevelDb会先往log文件里写入，成功后将记录插进Memtable中，这样基本就算完成了写入操作，因为一次写入操作只涉及一次磁盘顺序写和一次内存写入，所以这是为何说LevelDb写入速度极快的主要原因。 Log文件在系统中的作用主要是用于系统崩溃恢复而不丢失数据，假如没有Log文件，因为写入的记录刚开始是保存在内存中的，此时如果系统崩溃，内存中的数据还没有来得及Dump到磁盘，所以会丢失数据（Redis就存在这个问题）。为了避免这种情况，LevelDb在写入内存前先将操作记录到Log文件中，然后再记入内存中，这样即使系统崩溃，也可以从Log文件中恢复内存中的Memtable，不会造成数据的丢失。 当Memtable插入的数据占用内存到了一个界限后，需要将内存的记录导出到外存文件中，LevleDb会生成新的Log文件和Memtable，原先的Memtable就成为Immutable Memtable，顾名思义，就是说这个Memtable的内容是不可更改的，只能读不能写入或者删除。新到来的数据被记入新的Log文件和Memtable，LevelDb后台调度会将Immutable Memtable的数据导出到磁盘，形成一个新的SSTable文件。SSTable就是由内存中的数据不断导出并进行Compaction操作后形成的，而且SSTable的所有文件是一种层级结构，第一层为Level 0，第二层为Level 1，依次类推，层级逐渐增高，这也是为何称之为LevelDb的原因。 SSTable中的文件是Key有序的，就是说在文件中小key记录排在大Key记录之前，各个Level的SSTable都是如此，但是这里需要注意的一点是：Level 0的SSTable文件（后缀为.sst）和其它Level的文件相比有特殊性：这个层级内的.sst文件，两个文件可能存在key重叠，比如有两个level 0的sst文件，文件A和文件B，文件A的key范围是：{bar， car}，文件B的Key范围是{blue，samecity}，那么很可能两个文件都存在key=”blood”的记录。对于其它Level的SSTable文件来说，则不会出现同一层级内.sst文件的key重叠现象，就是说Level L中任意两个.sst文件，那么可以保证它们的key值是不会重叠的。这点需要特别注意，后面您会看到很多操作的差异都是由于这个原因造成的。 SSTable中的某个文件属于特定层级，而且其存储的记录是key有序的，那么必然有文件中的最小key和最大key，这是非常重要的信息，LevelDb应该记下这些信息。Manifest就是干这个的，它记载了SSTable各个文件的管理信息，比如属于哪个Level，文件名称叫啥，最小key和最大key各自是多少。下图是Manifest所存储内容的示意： 图中只显示了两个文件（manifest会记载所有SSTable文件的这些信息），即Level 0的test.sst1和test.sst2文件，同时记载了这些文件各自对应的key范围，比如test.sstt1的key范围是“an”到 “banana”，而文件test.sst2的key范围是“baby”到“samecity”，可以看出两者的key范围是有重叠的。 Current文件是干什么的呢？这个文件的内容只有一个信息，就是记载当前的manifest文件名。因为在LevleDb的运行过程中，随着Compaction的进行，SSTable文件会发生变化，会有新的文件产生，老的文件被废弃，Manifest也会跟着反映这种变化，此时往往会新生成Manifest文件来记载这种变化，而Current则用来指出哪个Manifest文件才是我们关心的那个Manifest文件。 以上介绍的内容就构成了LevelDb的整体静态结构，在LevelDb日知录接下来的内容中，我们会首先介绍重要文件或者内存数据的具体数据布局与结构。 Log文件上节内容讲到log文件在LevelDb中的主要作用是系统故障恢复时，能够保证不会丢失数据。因为在将记录写入内存的Memtable之前，会先写入Log文件，这样即使系统发生故障，Memtable中的数据没有来得及Dump到磁盘的SSTable文件，LevelDB也可以根据log文件恢复内存的Memtable数据结构内容，不会造成系统丢失数据，在这点上LevelDb和Bigtable是一致的。 下面我们带大家看看log文件的具体物理和逻辑布局是怎样的，LevelDb对于一个log文件，会把它切割成以32K为单位的物理Block，每次读取的单位以一个Block作为基本读取单位，下图展示的log文件由3个Block构成，所以从物理布局来讲，一个log文件就是由连续的32K大小Block构成的。 在应用的视野里是看不到这些Block的，应用看到的是一系列的Key:Value对，在LevelDb内部，会将一个Key:Value对看做一条记录的数据，另外在这个数据前增加一个记录头，用来记载一些管理信息，以方便内部处理，下图显示了一个记录在LevelDb内部是如何表示的。 记录头包含三个字段，ChechSum是对“类型”和“数据”字段的校验码，为了避免处理不完整或者是被破坏的数据，当LevelDb读取记录数据时候会对数据进行校验，如果发现和存储的CheckSum相同，说明数据完整无破坏，可以继续后续流程。“记录长度”记载了数据的大小，“数据”则是上面讲的Key:Value数值对，“类型”字段则指出了每条记录的逻辑结构和log文件物理分块结构之间的关系，具体而言，主要有以下四种类型：FULL/FIRST/MIDDLE/LAST。 如果记录类型是FULL，代表了当前记录内容完整地存储在一个物理Block里，没有被不同的物理Block切割开；如果记录被相邻的物理Block切割开，则类型会是其他三种类型中的一种。我们以之前图中所示的例子来具体说明。 假设目前存在三条记录，Record A，Record B和Record C，其中Record A大小为10K，Record B 大小为80K，Record C大小为12K，那么其在log文件中的逻辑布局会如图3.1所示。Record A是图中蓝色区域所示，因为大小为10K&lt;32K，能够放在一个物理Block中，所以其类型为FULL；Record B 大小为80K，而Block 1因为放入了Record A，所以还剩下22K，不足以放下Record B，所以在Block 1的剩余部分放入Record B的开头一部分，类型标识为FIRST，代表了是一个记录的起始部分；Record B还有58K没有存储，这些只能依次放在后续的物理Block里面，因为Block 2大小只有32K，仍然放不下Record B的剩余部分，所以Block 2全部用来放Record B，且标识类型为MIDDLE，意思是这是Record B中间一段数据；Record B剩下的部分可以完全放在Block 3中，类型标识为LAST，代表了这是Record B的末尾数据；图中黄色的Record C因为大小为12K，Block 3剩下的空间足以全部放下它，所以其类型标识为FULL。 从这个小例子可以看出逻辑记录和物理Block之间的关系，LevelDb一次物理读取为一个Block，然后根据类型情况拼接出逻辑记录，供后续流程处理。 SSTable文件SSTable是Bigtable中至关重要的一块，对于LevelDb来说也是如此，对LevelDb的SSTable实现细节的了解也有助于了解Bigtable中一些实现细节。 本节内容主要讲述SSTable的静态布局结构，我们曾在“LevelDb日知录之二：整体架构”中说过，SSTable文件形成了不同Level的层级结构，至于这个层级结构是如何形成的我们放在后面Compaction一节细说。本节主要介绍SSTable某个文件的物理布局和逻辑布局结构，这对了解LevelDb的运行过程很有帮助。 LevelDb不同层级有很多SSTable文件（以后缀.sst为特征），所有.sst文件内部布局都是一样的。上节介绍Log文件是物理分块的，SSTable也一样会将文件划分为固定大小的物理存储块，但是两者逻辑布局大不相同，根本原因是：Log文件中的记录是Key无序的，即先后记录的key大小没有明确大小关系，而.sst文件内部则是根据记录的Key由小到大排列的，从下面介绍的SSTable布局可以体会到Key有序是为何如此设计.sst文件结构的关键。 上图展示了一个.sst文件的物理划分结构，同Log文件一样，也是划分为固定大小的存储块，每个Block分为三个部分，黄色部分是数据存储区， 蓝色的Type区用于标识数据存储区是否采用了数据压缩算法（Snappy压缩或者无压缩两种），CRC部分则是数据校验码，用于判别数据是否在生成和传输中出错。 以上是.sst的物理布局，下面介绍.sst文件的逻辑布局，所谓逻辑布局，就是说尽管大家都是物理块，但是每一块存储什么内容，内部又有什么结构等。下面展示了.sst文件的内部逻辑解释。 图4.2 逻辑布局 从上图可以看出，从大的方面，可以将.sst文件划分为数据存储区和数据管理区，数据存储区存放实际的Key:Value数据，数据管理区则提供一些索引指针等管理数据，目的是更快速便捷的查找相应的记录。两个区域都是在上述的分块基础上的，就是说文件的前面若干块实际存储KV数据，后面数据管理区存储管理数据。管理数据又分为四种不同类型： Meta Block MetaBlock 索引 Index Block数据索引块 Footer文件尾部块 LevelDb 1.2版对于Meta Block尚无实际使用，只是保留了一个接口，估计会在后续版本中加入内容，下面我们看看数据索引区和文件尾部Footer的内部结构。 图4.3 数据索引 上图是数据索引的内部结构示意图。再次强调一下，Data Block内的KV记录是按照Key由小到大排列的，数据索引区的每条记录是对某个Data Block建立的索引信息，每条索引信息包含三个内容，以数据块i的索引Index i来说： 红色部分的第一个字段记载大于等于数据块i中最大的Key值的那个Key; 第二个字段指出数据块i在.sst文件中的起始位置; 第三个字段指出Data Block i的大小（有时候是有数据压缩的）。 后面两个字段好理解，是用于定位数据块在文件中的位置的，第一个字段需要详细解释一下，在索引里保存的这个Key值未必一定是某条记录的Key，以上图的例子来说，假设数据块i 的最小Key=“samecity”，最大Key=“the best”;数据块i+1的最小Key=“the fox”，最大Key=“zoo”，那么对于数据块i的索引Index i来说，其第一个字段记载大于等于数据块i的最大Key(“the best”)同时要小于数据块i+1的最小Key(“the fox”)，所以例子中Index i的第一个字段是：“the c”，这个是满足要求的；而Index i+1的第一个字段则是“zoo”，即数据块i+1的最大Key。 文件末尾Footer块的内部结构见下图，metaindex_handle指出了metaindex block的起始位置和大小；inex_handle指出了index Block的起始地址和大小；这两个字段可以理解为索引的索引，是为了正确读出索引值而设立的，后面跟着一个填充区和魔数。 图4.4 Footer 上面主要介绍的是数据管理区的内部结构，下面我们看看数据区的一个Block的数据部分内部是如何布局的（图4.1中的h黄色部分），图4.5是其内部布局示意图。 图4.5 数据Block内部结构 从图中可以看出，其内部也分为两个部分，前面是一个个KV记录，其顺序是根据Key值由小到大排列的，在Block尾部则是一些“重启点”（Restart Point）,其实是一些指针，指出Block内容中的一些记录位置。 “重启点”是干什么的呢？我们一再强调，Block内容里的KV记录是按照Key大小有序的，这样的话，相邻的两条记录很可能Key部分存在重叠，比如key i=“the Car”，Key i+1=“the color”,那么两者存在重叠部分“the c”，为了减少Key的存储量，Key i+1可以只存储和上一条Key不同的部分“olor”，两者的共同部分从Key i中可以获得。记录的Key在Block内容部分就是这么存储的，主要目的是减少存储开销。“重启点”的意思是：在这条记录开始，不再采取只记载不同的Key部分，而是重新记录所有的Key值，假设Key i+1是一个重启点，那么Key里面会完整存储“the color”，而不是采用简略的“olor”方式。Block尾部就是指出哪些记录是这些重启点的。 图4.6 记录格式 在Block内容区，每个KV记录的内部结构是怎样的？图4.6给出了其详细结构，每个记录包含5个字段：key共享长度，比如上面的“olor”记录， 其key和上一条记录共享的Key部分长度是“the c”的长度，即5；key非共享长度，对于“olor”来说，是4；value长度指出Key:Value中Value的长度，在后面的Value内容字段中存储实际的Value值；而key非共享内容则实际存储“olor”这个Key字符串。 上面讲的这些就是.sst文件的全部内部奥秘。 MemTable详解LevelDb日知录前述小节大致讲述了磁盘文件相关的重要静态结构，本小节讲述内存中的数据结构Memtable，Memtable在整个体系中的重要地位也不言而喻。总体而言，所有KV数据都是存储在Memtable，Immutable Memtable和SSTable中的，Immutable Memtable从结构上讲和Memtable是完全一样的，区别仅仅在于其是只读的，不允许写入操作，而Memtable则是允许写入和读取的。当Memtable写入的数据占用内存到达指定数量，则自动转换为Immutable Memtable，等待Dump到磁盘中，系统会自动生成新的Memtable供写操作写入新数据，理解了Memtable，那么Immutable Memtable自然不在话下。 LevelDb的MemTable提供了将KV数据写入，删除以及读取KV记录的操作接口，但是事实上Memtable并不存在真正的删除操作,删除某个Key的Value在Memtable内是作为插入一条记录实施的，但是会打上一个Key的删除标记，真正的删除操作是Lazy的，会在以后的Compaction过程中去掉这个KV。 需要注意的是，LevelDb的Memtable中KV对是根据Key大小有序存储的，在系统插入新的KV时，LevelDb要把这个KV插到合适的位置上以保持这种Key有序性。其实，LevelDb的Memtable类只是一个接口类，真正的操作是通过背后的SkipList来做的，包括插入操作和读取操作等，所以Memtable的核心数据结构是一个SkipList。 SkipList是由William Pugh发明。他在Communications of the ACM June 1990, 33(6) 668-676 发表了Skip lists: a probabilistic alternative to balanced trees，在该论文中详细解释了SkipList的数据结构和插入删除操作。 SkipList是平衡树的一种替代数据结构，但是和红黑树不相同的是，SkipList对于树的平衡的实现是基于一种随机化的算法的，这样也就是说SkipList的插入和删除的工作是比较简单的。 关于SkipList的详细介绍可以参考这篇文章：http://www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html，讲述的很清楚，LevelDb的SkipList基本上是一个具体实现，并无特殊之处。 SkipList不仅是维护有序数据的一个简单实现，而且相比较平衡树来说，在插入数据的时候可以避免频繁的树节点调整操作，所以写入效率是很高的，LevelDb整体而言是个高写入系统，SkipList在其中应该也起到了很重要的作用。Redis为了加快插入操作，也使用了SkipList来作为内部实现数据结构。 写入与删除记录在之前的五节LevelDb日知录中，我们介绍了LevelDb的一些静态文件及其详细布局，从本节开始，我们看看LevelDb的一些动态操作，比如读写记录，Compaction，错误恢复等操作。 本节介绍levelDb的记录更新操作，即插入一条KV记录或者删除一条KV记录。levelDb的更新操作速度是非常快的，源于其内部机制决定了这种更新操作的简单性。 图6.1 LevelDb写入记录 图6.1是levelDb如何更新KV数据的示意图，从图中可以看出，对于一个插入操作Put(Key,Value)来说，完成插入操作包含两个具体步骤：首先是将这条KV记录以顺序写的方式追加到之前介绍过的log文件末尾，因为尽管这是一个磁盘读写操作，但是文件的顺序追加写入效率是很高的，所以并不会导致写入速度的降低；第二个步骤是:如果写入log文件成功，那么将这条KV记录插入内存中的Memtable中，前面介绍过，Memtable只是一层封装，其内部其实是一个Key有序的SkipList列表，插入一条新记录的过程也很简单，即先查找合适的插入位置，然后修改相应的链接指针将新记录插入即可。完成这一步，写入记录就算完成了，所以一个插入记录操作涉及一次磁盘文件追加写和内存SkipList插入操作，这是为何levelDb写入速度如此高效的根本原因。 从上面的介绍过程中也可以看出：log文件内是key无序的，而Memtable中是key有序的。那么如果是删除一条KV记录呢？对于levelDb来说，并不存在立即删除的操作，而是与插入操作相同的，区别是，插入操作插入的是Key:Value 值，而删除操作插入的是“Key:删除标记”，并不真正去删除记录，而是后台Compaction的时候才去做真正的删除操作。 levelDb的写入操作就是如此简单。真正的麻烦在后面将要介绍的读取操作中。 读取记录LevelDb是针对大规模Key/Value数据的单机存储库，从应用的角度来看，LevelDb就是一个存储工具。而作为称职的存储工具，常见的调用接口无非是新增KV，删除KV，读取KV，更新Key对应的Value值这么几种操作。LevelDb的接口没有直接支持更新操作的接口，如果需要更新某个Key的Value,你可以选择直接生猛地插入新的KV，保持Key相同，这样系统内的key对应的value就会被更新；或者你可以先删除旧的KV， 之后再插入新的KV，这样比较委婉地完成KV的更新操作。 假设应用提交一个Key值，下面我们看看LevelDb是如何从存储的数据中读出其对应的Value值的。图7-1是LevelDb读取过程的整体示意图。 图7-1 LevelDb读取记录流程 LevelDb首先会去查看内存中的Memtable，如果Memtable中包含key及其对应的value，则返回value值即可；如果在Memtable没有读到key，则接下来到同样处于内存中的Immutable Memtable中去读取，类似地，如果读到就返回，若是没有读到,那么只能万般无奈下从磁盘中的大量SSTable文件中查找。因为SSTable数量较多，而且分成多个Level，所以在SSTable中读数据是相当蜿蜒曲折的一段旅程。总的读取原则是这样的：首先从属于level 0的文件中查找，如果找到则返回对应的value值，如果没有找到那么到level 1中的文件中去找，如此循环往复，直到在某层SSTable文件中找到这个key对应的value为止（或者查到最高level，查找失败，说明整个系统中不存在这个Key)。 那么为什么是从Memtable到Immutable Memtable，再从Immutable Memtable到文件，而文件中为何是从低level到高level这么一个查询路径呢？道理何在？之所以选择这么个查询路径，是因为从信息的更新时间来说，很明显Memtable存储的是最新鲜的KV对；Immutable Memtable中存储的KV数据对的新鲜程度次之；而所有SSTable文件中的KV数据新鲜程度一定不如内存中的Memtable和Immutable Memtable的。对于SSTable文件来说，如果同时在level L和Level L+1找到同一个key，level L的信息一定比level L+1的要新。也就是说，上面列出的查找路径就是按照数据新鲜程度排列出来的，越新鲜的越先查找。 为啥要优先查找新鲜的数据呢？这个道理不言而喻，举个例子。比如我们先往levelDb里面插入一条数据 {key=”www.samecity.com” value=”我们”},过了几天，samecity网站改名为：69同城，此时我们插入数据{key=”www.samecity.com” value=”69同城”}，同样的key,不同的value；逻辑上理解好像levelDb中只有一个存储记录，即第二个记录，但是在levelDb中很可能存在两条记录，即上面的两个记录都在levelDb中存储了，此时如果用户查询key=”www.samecity.com”,我们当然希望找到最新的更新记录，也就是第二个记录返回，这就是为何要优先查找新鲜数据的原因。 前文有讲：对于SSTable文件来说，如果同时在level L和Level L+1找到同一个key，level L的信息一定比level L+1的要新。这是一个结论，理论上需要一个证明过程，否则会招致如下的问题：为神马呢？从道理上讲呢，很明白：因为Level L+1的数据不是从石头缝里蹦出来的，也不是做梦梦到的，那它是从哪里来的？Level L+1的数据是从Level L 经过Compaction后得到的（如果您不知道什么是Compaction，那么……..也许以后会知道的），也就是说，您看到的现在的Level L+1层的SSTable数据是从原来的Level L中来的，现在的Level L比原来的Level L数据要新鲜，所以可证，现在的Level L比现在的Level L+1的数据要新鲜。 SSTable文件很多，如何快速地找到key对应的value值？在LevelDb中，level 0一直都爱搞特殊化，在level 0和其它level中查找某个key的过程是不一样的。因为level 0下的不同文件可能key的范围有重叠，某个要查询的key有可能多个文件都包含，这样的话LevelDb的策略是先找出level 0中哪些文件包含这个key（manifest文件中记载了level和对应的文件及文件里key的范围信息，LevelDb在内存中保留这种映射表）， 之后按照文件的新鲜程度排序，新的文件排在前面，之后依次查找，读出key对应的value。而如果是非level 0的话，因为这个level的文件之间key是不重叠的，所以只从一个文件就可以找到key对应的value。 最后一个问题,如果给定一个要查询的key和某个key range包含这个key的SSTable文件，那么levelDb是如何进行具体查找过程的呢？levelDb一般会先在内存中的Cache中查找是否包含这个文件的缓存记录，如果包含，则从缓存中读取；如果不包含，则打开SSTable文件，同时将这个文件的索引部分加载到内存中并放入Cache中。 这样Cache里面就有了这个SSTable的缓存项，但是只有索引部分在内存中，之后levelDb根据索引可以定位到哪个内容Block会包含这条key，从文件中读出这个Block的内容，在根据记录一一比较，如果找到则返回结果，如果没有找到，那么说明这个level的SSTable文件并不包含这个key，所以到下一级别的SSTable中去查找。 从之前介绍的LevelDb的写操作和这里介绍的读操作可以看出，相对写操作，读操作处理起来要复杂很多，所以写的速度必然要远远高于读数据的速度，也就是说，LevelDb比较适合写操作多于读操作的应用场合。而如果应用是很多读操作类型的，那么顺序读取效率会比较高，因为这样大部分内容都会在缓存中找到，尽可能避免大量的随机读取操作。 Compaction操作前文有述，对于LevelDb来说，写入记录操作很简单，删除记录仅仅写入一个删除标记就算完事，但是读取记录比较复杂，需要在内存以及各个层级文件中依照新鲜程度依次查找，代价很高。为了加快读取速度，levelDb采取了compaction的方式来对已有的记录进行整理压缩，通过这种方式，来删除掉一些不再有效的KV数据，减小数据规模，减少文件数量等。 levelDb的compaction机制和过程与Bigtable所讲述的是基本一致的，Bigtable中讲到三种类型的compaction: minor ，major和full。所谓minor Compaction，就是把memtable中的数据导出到SSTable文件中；major compaction就是合并不同层级的SSTable文件，而full compaction就是将所有SSTable进行合并。 LevelDb包含其中两种，minor和major。 我们将为大家详细叙述其机理。 先来看看minor Compaction的过程。Minor compaction 的目的是当内存中的memtable大小到了一定值时，将内容保存到磁盘文件中，图8.1是其机理示意图。 图8.1 minor compaction 从8.1可以看出，当memtable数量到了一定程度会转换为immutable memtable，此时不能往其中写入记录，只能从中读取KV内容。之前介绍过，immutable memtable其实是一个多层级队列SkipList，其中的记录是根据key有序排列的。所以这个minor compaction实现起来也很简单，就是按照immutable memtable中记录由小到大遍历，并依次写入一个level 0 的新建SSTable文件中，写完后建立文件的index 数据，这样就完成了一次minor compaction。从图中也可以看出，对于被删除的记录，在minor compaction过程中并不真正删除这个记录，原因也很简单，这里只知道要删掉key记录，但是这个KV数据在哪里?那需要复杂的查找，所以在minor compaction的时候并不做删除，只是将这个key作为一个记录写入文件中，至于真正的删除操作，在以后更高层级的compaction中会去做。 当某个level下的SSTable文件数目超过一定设置值后，levelDb会从这个level的SSTable中选择一个文件（level&gt;0），将其和高一层级的level+1的SSTable文件合并，这就是major compaction。 我们知道在大于0的层级中，每个SSTable文件内的Key都是由小到大有序存储的，而且不同文件之间的key范围（文件内最小key和最大key之间）不会有任何重叠。Level 0的SSTable文件有些特殊，尽管每个文件也是根据Key由小到大排列，但是因为level 0的文件是通过minor compaction直接生成的，所以任意两个level 0下的两个sstable文件可能再key范围上有重叠。所以在做major compaction的时候，对于大于level 0的层级，选择其中一个文件就行，但是对于level 0来说，指定某个文件后，本level中很可能有其他SSTable文件的key范围和这个文件有重叠，这种情况下，要找出所有有重叠的文件和level 1的文件进行合并，即level 0在进行文件选择的时候，可能会有多个文件参与major compaction。 levelDb在选定某个level进行compaction后，还要选择是具体哪个文件要进行compaction，levelDb在这里有个小技巧， 就是说轮流来，比如这次是文件A进行compaction，那么下次就是在key range上紧挨着文件A的文件B进行compaction，这样每个文件都会有机会轮流和高层的level 文件进行合并。 如果选好了level L的文件A和level L+1层的文件进行合并，那么问题又来了，应该选择level L+1哪些文件进行合并？levelDb选择L+1层中和文件A在key range上有重叠的所有文件来和文件A进行合并。 也就是说，选定了level L的文件A,之后在level L+1中找到了所有需要合并的文件B,C,D…..等等。剩下的问题就是具体是如何进行major 合并的？就是说给定了一系列文件，每个文件内部是key有序的，如何对这些文件进行合并，使得新生成的文件仍然Key有序，同时抛掉哪些不再有价值的KV 数据。 图8.2说明了这一过程。 图8.2 SSTable Compaction Major compaction的过程如下：对多个文件采用多路归并排序的方式，依次找出其中最小的Key记录，也就是对多个文件中的所有记录重新进行排序。之后采取一定的标准判断这个Key是否还需要保存，如果判断没有保存价值，那么直接抛掉，如果觉得还需要继续保存，那么就将其写入level L+1层中新生成的一个SSTable文件中。就这样对KV数据一一处理，形成了一系列新的L+1层数据文件，之前的L层文件和L+1层参与compaction 的文件数据此时已经没有意义了，所以全部删除。这样就完成了L层和L+1层文件记录的合并过程。 那么在major compaction过程中，判断一个KV记录是否抛弃的标准是什么呢？其中一个标准是:对于某个key来说，如果在小于L层中存在这个Key，那么这个KV在major compaction过程中可以抛掉。因为我们前面分析过，对于层级低于L的文件中如果存在同一Key的记录，那么说明对于Key来说，有更新鲜的Value存在，那么过去的Value就等于没有意义了，所以可以删除。 levelDb中的Cache书接前文，前面讲过对于levelDb来说，读取操作如果没有在内存的memtable中找到记录，要多次进行磁盘访问操作。假设最优情况，即第一次就在level 0中最新的文件中找到了这个key，那么也需要读取2次磁盘，一次是将SSTable的文件中的index部分读入内存，这样根据这个index可以确定key是在哪个block中存储；第二次是读入这个block的内容，然后在内存中查找key对应的value。 levelDb中引入了两个不同的Cache:Table Cache和Block Cache。其中Block Cache是配置可选的，即在配置文件中指定是否打开这个功能。 图9.1 table cache 图9.1是table cache的结构。在Cache中，key值是SSTable的文件名称，Value部分包含两部分，一个是指向磁盘打开的SSTable文件的文件指针，这是为了方便读取内容；另外一个是指向内存中这个SSTable文件对应的Table结构指针，table结构在内存中，保存了SSTable的index内容以及用来指示block cache用的cache_id ,当然除此外还有其它一些内容。 比如在get(key)读取操作中，如果levelDb确定了key在某个level下某个文件A的key range范围内，那么需要判断是不是文件A真的包含这个KV。此时，levelDb会首先查找Table Cache，看这个文件是否在缓存里，如果找到了，那么根据index部分就可以查找是哪个block包含这个key。如果没有在缓存中找到文件，那么打开SSTable文件，将其index部分读入内存，然后插入Cache里面，去index里面定位哪个block包含这个Key 。如果确定了文件哪个block包含这个key，那么需要读入block内容，这是第二次读取。 图9.2 block cache Block Cache是为了加快这个过程的，图9.2是其结构示意图。其中的key是文件的cache_id加上这个block在文件中的起始位置block_offset。而value则是这个Block的内容。 如果levelDb发现这个block在block cache中，那么可以避免读取数据，直接在cache里的block内容里面查找key的value就行，如果没找到呢？那么读入block内容并把它插入block cache中。levelDb就是这样通过两个cache来加快读取速度的。从这里可以看出，如果读取的数据局部性比较好，也就是说要读的数据大部分在cache里面都能读到，那么读取效率应该还是很高的，而如果是对key进行顺序读取效率也应该不错，因为一次读入后可以多次被复用。但是如果是随机读取，您可以推断下其效率如何。 Version、VersionEdit、VersionSetVersion 保存了当前磁盘以及内存中所有的文件信息，一般只有一个Version叫做”current” version（当前版本）。Leveldb还保存了一系列的历史版本，这些历史版本有什么作用呢？ 当一个Iterator创建后，Iterator就引用到了current version(当前版本)，只要这个Iterator不被delete那么被Iterator引用的版本就会一直存活。这就意味着当你用完一个Iterator后，需要及时删除它。 当一次Compaction结束后（会生成新的文件，合并前的文件需要删除），Leveldb会创建一个新的版本作为当前版本，原先的当前版本就会变为历史版本。 VersionSet 是所有Version的集合，管理着所有存活的Version。 VersionEdit 表示Version之间的变化，相当于delta 增量，表示有增加了多少文件，删除了文件。下图表示他们之间的关系。 Version0 +VersionEdit–&gt;Version1 VersionEdit会保存到MANIFEST文件中，当做数据恢复时就会从MANIFEST文件中读出来重建数据。 leveldb的这种版本的控制，让我想到了双buffer切换，双buffer切换来自于图形学中，用于解决屏幕绘制时的闪屏问题，在服务器编程中也有用处。 比如我们的服务器上有一个字典库，每天我们需要更新这个字典库，我们可以新开一个buffer，将新的字典库加载到这个新buffer中，等到加载完毕，将字典的指针指向新的字典库。 leveldb的version管理和双buffer切换类似，但是如果原version被某个iterator引用，那么这个version会一直保持，直到没有被任何一个iterator引用，此时就可以删除这个version。 参考Leveldb 实现原理]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how-the-append-only-btree-work]]></title>
    <url>%2F2017%2F08%2F23%2Fhow-the-append-only-btree-work%2F</url>
    <content type="text"><![CDATA[原文：http://www.bzero.se/ldapd/btree.html 该 tree 也被称为 Copy-On-Write Tree考虑下图的这个3层 b tree.该树由两层的 branch page（root 也是一个 branch page）和 5 个 leaf page 组成。key 和 data 都存储在 leaf page 里面。 这里，leaf chaining（叶节点之间的指针连接）并没有被支持，也就是叶子节点之间的顺序 access 特性不被支持（即没有指针从一个 leaf 指向下一个 leaf），这是因为该特性的实现，会要求每次 update 都去 rewrite 整个 tree。 该 tree 的 page 在 database 文件中，被顺序存储着。添加 page numbers 也只是意味着增加 file 的 offset（类似于给vector数组后面添加一个位置一样）。 meta page ？包括： 一个指向 root page 的指针 一个 SHA1 hash 一个静态计数器（全局计数器）？ 当一个 file 被打开，它将会被从尾部的 page 开始扫描，直到找到一个有效的 meta page，从而根据上述的指针，找到 root page。 比如现在要更新 leaf page 8 上的值，不同于直接在该 page 上进行更改覆写，这里会直接产生一个具有 new value 的 page，并 append 到 file 尾部。如下图中的 page 12。 因为原本作为 leaf page 8 的位置，修改到了 page 12，它的每个 parent page 都需要更新对应的指针。 leaf 7 没有被影响。而 branch 6 作为被修改 leaf 的 parent，其指针值被影响了，所以一个新的 page 被创建出来 – branch page 11，同时一个新的 root 也被创建出来 – root 13，更新后的 tree 如上图所示。 这样，任何拥有 root page 9 的用户，仍然能够跟踪到没有被修改之前的值。这就是 database 自己的一个 snapshot。 在该 database file 中，新 page 只是不断的被 append 到 file 尾部，已经写入值的 page 并不会被影响。 修改一次数据后，当每个相关的 page 都被更新完毕，就会产生一个新的 meta page，指向新的 root page，如下图： 从结果上看，对一个page的修改（修改 leaf page 8），会导致 4 个新 page 被 append 到 file 尾部。这在一定程度上浪费了磁盘空间，但是这样顺序写操作，能够非常大的提升随即写性能。并且这里并不需要再记录 transaction log，用于数据恢复，该 database file 本身，就是一个 transaction log。]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[inode相关命令]]></title>
    <url>%2F2017%2F08%2F20%2F2017-08-20-inode-command%2F</url>
    <content type="text"><![CDATA[​touch：新建文件ls -i：显示文件的inodestat filename：显示文件的所有状态信息，包括大小，inode id，link 数目，创建时间，修改时间等ln file1 filelink1：给file1创建一个名字叫做filelink1的链接，具有相同的 inode id如果有一个文件名很奇怪，无法使用正常的 rm 命令删除，比如：“ab*那么可以使用 find . -inum xxxx -delete 命令删除df -i：查看inode资源的使用情况可以清楚看到inode的最大使用数目。 也可以使用 find 命令找出文件所在目录]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>storage</tag>
        <tag>linux-cmd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二章-IO大法]]></title>
    <url>%2F2017%2F08%2F16%2F2017-08-16-talking-storage-chapter2%2F</url>
    <content type="text"><![CDATA[IO大法PCIPCI是Peripheral Component Interconnect(外设部件互连标准)。其连接在南桥上。北桥连接系统内存，CPU以及高速总线（ex. PCIE）。PCI的地址总线和数据总线是时分复用（Time Division Multiplexing，TDM），即采用同一物理连接的不同时段来传输不同的信号。 数据传输时，分为传输的发起者（Master）和数据的接受者（Slave），同一时刻只有一对设备可以传输数据。 中断共享硬件上，采用电平触发（PCI板卡设备用三极管拉低信号）软件上，采用中断链（如果多个板卡共享一个中断，那么一个中断处理函数结束会指向下一个处理函数，发生中断时候，逐个检查，是则处理，不是则跳过） 数据通信CPU向存储所在的地址（比如0x0A）发送命令。 发送读（/写）命令 指明LBA（硬盘逻辑区块） 指明读取的内容到哪一段内存。 第一条指令指定了读时配置：完成是否触发中断，是否启用磁盘缓存。。。 第二条指令进行磁盘的逻辑区块到实际区块查找，转到该扇区，读取数据 第三条指令，在数据读出以后，会进入 DMA 操作，不需要 CPU 接入，读取结束，CPU从内存读取数据，并进行计算。]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>storage</tag>
        <tag>大话存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算图形学中的微积分-反向传播算法]]></title>
    <url>%2F2017%2F04%2F09%2F2017-04-09-Calculus-on-Computational-Graphs%2F</url>
    <content type="text"><![CDATA[目录{:toc} IntroductionBackpropagation is the key algorithm that makes training deep models computationally tractable. For modern neural networks, it can make training with gradient descent as much as ten million times faster, relative to a naive implementation. That’s the difference between a model taking a week to train and taking 200,000 years. Beyond its use in deep learning, backpropagation is a powerful computational tool in many other areas, ranging from weather forecasting to analyzing numerical stability – it just goes by different names. In fact, the algorithm has been reinvented at least dozens of times in different fields (see Griewank (2010)). The general, application independent, name is “reverse-mode differentiation.” Fundamentally, it’s a technique for calculating derivatives quickly. And it’s an essential trick to have in your bag, not only in deep learning, but in a wide variety of numerical computing situations. Computational GraphsComputational graphs are a nice way to think about mathematical expressions. For example, consider the expression e=(a+b)*(b+1). There are three operations: two additions and one multiplication. To help us talk about this, let’s introduce two intermediary variables, c and d so that every function’s output has a variable. We now have: $$c=a+b$$ $$d=b+1$$ $$e=c*d$$ To create a computational graph, we make each of these operations, along with the input variables, into nodes. When one node’s value is the input to another node, an arrow goes from one to another. These sorts of graphs come up all the time in computer science, especially in talking about functional programs. They are very closely related to the notions of dependency graphs and call graphs. They’re also the core abstraction behind the popular deep learning framework Theano. We can evaluate the expression by setting the input variables to certain values and computing nodes up through the graph. For example, let’s set a=2 and b=1: The expression evaluates to 6. Derivatives on Computational GraphsIf one wants to understand derivatives in a computational graph, the key is to understand derivatives on the edges. If a directly affects c, then we want to know how it affects c. If a changes a little bit, how does c change? We call this the partial derivative of c with respect to a. To evaluate the partial derivatives in this graph, we need the sum rule and the product rule: $$\frac{\partial}{\partial a}(a+b) = \frac{\partial a}{\partial a} + \frac{\partial b}{\partial a} = 1$$ $$\frac{\partial}{\partial u}uv = u\frac{\partial v}{\partial u} + v\frac{\partial u}{\partial u} = v$$ Below, the graph has the derivative on each edge labeled. What if we want to understand how nodes that aren’t directly connected affect each other? Let’s consider how e is affected by a. If we change a at a speed of 1, c also changes at a speed of 1. In turn, c changing at a speed of 1 causes e to change at a speed of 2. So e changes at a rate of 1∗2 with respect to a. The general rule is to sum over all possible paths from one node to the other, multiplying the derivatives on each edge of the path together. For example, to get the derivative of ee with respect to b we get: $$\frac{\partial e}{\partial b}= 12 + 13$$ This accounts for how b affects e through c and also how it affects it through d. This general “sum over paths” rule is just a different way of thinking about the multivariate chain rule. Factoring PathsThe problem with just “summing over the paths” is that it’s very easy to get a combinatorial explosion in the number of possible paths. In the above diagram, there are three paths from X to Y, and a further three paths from Y to Z. If we want to get the derivative $\frac{\partial Z}{\partial X}$ by summing over all paths, we need to sum over 3∗3=9 paths: $$\frac{\partial Z}{\partial X} = \alpha\delta + \alpha\epsilon + \alpha\zeta + \beta\delta + \beta\epsilon + \beta\zeta + \gamma\delta + \gamma\epsilon + \gamma\zeta$$ The above only has nine paths, but it would be easy to have the number of paths to grow exponentially as the graph becomes more complicated. Instead of just naively summing over the paths, it would be much better to factor them: $$\frac{\partial Z}{\partial X} = (\alpha + \beta + \gamma)(\delta + \epsilon + \zeta)$$ This is where “forward-mode differentiation” and “reverse-mode differentiation” come in. They’re algorithms for efficiently computing the sum by factoring the paths. Instead of summing over all of the paths explicitly, they compute the same sum more efficiently by merging paths back together at every node. In fact, both algorithms touch each edge exactly once! Forward-mode differentiation starts at an input to the graph and moves towards the end. At every node, it sums all the paths feeding in. Each of those paths represents one way in which the input affects that node. By adding them up, we get the total way in which the node is affected by the input, it’s derivative. Though you probably didn’t think of it in terms of graphs, forward-mode differentiation is very similar to what you implicitly learned to do if you took an introduction to calculus class. Reverse-mode differentiation, on the other hand, starts at an output of the graph and moves towards the beginning. At each node, it merges all paths which originated at that node. Forward-mode differentiation tracks how one input affects every node. Reverse-mode differentiation tracks how every node affects one output. That is, forward-mode differentiation applies the operator $\frac{\partial}{\partial X}$ to every node, while reverse mode differentiation applies the operator $\frac{\partial Z}{\partial}$ to every node Computational VictoriesAt this point, you might wonder why anyone would care about reverse-mode differentiation. It looks like a strange way of doing the same thing as the forward-mode. Is there some advantage? Let’s consider our original example again: We can use forward-mode differentiation from b up. This gives us the derivative of every node with respect to b. We’ve computed $\frac{\partial e}{\partial b}$, the derivative of our output with respect to one of our inputs. What if we do reverse-mode differentiation from $e$ down? This gives us the derivative of $e$ with respect to every node: When I say that reverse-mode differentiation gives us the derivative of e with respect to every node, I really do mean every node. We get both $\frac{\partial e}{\partial a}$ and $\frac{\partial e}{\partial b}$, the derivatives of $e$ with respect to both inputs. Forward-mode differentiation gave us the derivative of our output with respect to a single input, but reverse-mode differentiation gives us all of them. For this graph, that’s only a factor of two speed up, but imagine a function with a million inputs and one output. Forward-mode differentiation would require us to go through the graph a million times to get the derivatives. Reverse-mode differentiation can get them all in one fell swoop! A speed up of a factor of a million is pretty nice! When training neural networks, we think of the cost (a value describing how bad a neural network performs) as a function of the parameters (numbers describing how the network behaves). We want to calculate the derivatives of the cost with respect to all the parameters, for use in gradient descent. Now, there’s often millions, or even tens of millions of parameters in a neural network. So, reverse-mode differentiation, called backpropagation in the context of neural networks, gives us a massive speed up! (Are there any cases where forward-mode differentiation makes more sense? Yes, there are! Where the reverse-mode gives the derivatives of one output with respect to all inputs, the forward-mode gives us the derivatives of all outputs with respect to one input. If one has a function with lots of outputs, forward-mode differentiation can be much, much, much faster.) Isn’t This Trivial?When I first understood what backpropagation was, my reaction was: “Oh, that’s just the chain rule! How did it take us so long to figure out?” I’m not the only one who’s had that reaction. It’s true that if you ask “is there a smart way to calculate derivatives in feedforward neural networks?” the answer isn’t that difficult. But I think it was much more difficult than it might seem. You see, at the time backpropagation was invented, people weren’t very focused on the feedforward neural networks that we study. It also wasn’t obvious that derivatives were the right way to train them. Those are only obvious once you realize you can quickly calculate derivatives. There was a circular dependency. Worse, it would be very easy to write off any piece of the circular dependency as impossible on casual thought. Training neural networks with derivatives? Surely you’d just get stuck in local minima. And obviously it would be expensive to compute all those derivatives. It’s only because we know this approach works that we don’t immediately start listing reasons it’s likely not to. That’s the benefit of hindsight. Once you’ve framed the question, the hardest work is already done. ConclusionDerivatives are cheaper than you think. That’s the main lesson to take away from this post. In fact, they’re unintuitively cheap, and us silly humans have had to repeatedly rediscover this fact. That’s an important thing to understand in deep learning. It’s also a really useful thing to know in other fields, and only more so if it isn’t common knowledge. Are there other lessons? I think there are. Backpropagation is also a useful lens for understanding how derivatives flow through a model. This can be extremely helpful in reasoning about why some models are difficult to optimize. The classic example of this is the problem of vanishing gradients in recurrent neural networks. Finally, I claim there is a broad algorithmic lesson to take away from these techniques. Backpropagation and forward-mode differentiation use a powerful pair of tricks (linearization and dynamic programming) to compute derivatives more efficiently than one might think possible. If you really understand these techniques, you can use them to efficiently calculate several other interesting expressions involving derivatives. We’ll explore this in a later blog post. This post gives a very abstract treatment of backpropagation. I strongly recommend reading Michael Nielsen’s chapter on it for an excellent discussion, more concretely focused on neural networks. ReferenceCalculus on Computational Graphs: Backpropagation]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建tensorflow开发环境]]></title>
    <url>%2F2017%2F04%2F09%2F2017-04-09-Install-tensorflow-devEnv%2F</url>
    <content type="text"><![CDATA[笔者使用的是windows 10 系统。下面会使用docker来安装 tensorflow。 安装 docker对于window下docker 的安装，直接进入官网 https://www.docker.com/docker-windows 下载安装包。需要注意的是，docker for windows 支持的是 64bit 操作系统。所以 32bit 的系统的环境，暂时这种方式还不支持。 安装 tensorflow使用命令1docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow 就会自动从 http://gcr.io 上，下载 tensorflow 的镜像并运行，等待下载安装结束，直接在浏览器中输入 localhost:8888 进行访问。 就会进入 Jupyter Notebook 应用。Jupter Notebook 是一个开源的 web 应用，是一款交互式的笔记。它可以在线运行输入的代码，并实时显示结果。所以我们可以在 Jupter Notebook 中，编写我们的 tensorflow 代码，同时可以直接看到代码运行结果。 代码编写这里我们尝试修改例程 1_hello_tensorflow_ipynb 的代码，并用快捷键 ctrl+Enter 查看代码运行结果。 我们这里尝试修改 input2 的向量为 [2, 2, 4] ，并使用快捷键 ctrl+Enter 查看二者相加的结果： 可以看到 input1 和 input2 相加的结果已经变成了 [3, 3, 3, 5] 。 参考 Jupter Notebook Jupyter Notebook 快速入门]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jekyll使用总结]]></title>
    <url>%2F2017%2F04%2F06%2F2017-04-06-jekyll-using%2F</url>
    <content type="text"><![CDATA[全局变量categories当文章设置了 categories 属性以后，访问该文章时候就会归入对应的 url 路径。比如设置了：categories: [&#39;Life&#39;]，那么访问该文章的时候，URL路径就是 http://webname/`Life`/…比如设置了：categories: [&#39;Life&#39;, &#39;eassy&#39;]，那么访问该文章的时候，URL路径就是 http://webname/`Life`/`essay`/…因为 ｛% 会被 jekyll 解析成内部语法，所以用中文字符 ｛ 替换了 英文字符 { 。123456｛% for category in site.categories %｝ ｛｛ category [0] ｝｝ 是 category name ｛｛ category [1] ｝｝ 包含 category 下的 posts ｛\% endfor %｝ tags123456｛\% for tag in site.tags %｝ ｛｛ tag[0] ｝｝是 tag name ｛｛ tag[1] ｝｝包含 tag 下的 posts ｛% endfor %｝ 过滤器使用生成二级目录categories作为一级目录tags作为二级目录12345678910111213｛% for category in site.categories %｝ &lt;ul&gt; ｛｛ category[0] ｝｝ (｛｛ category[1].size｝｝) &lt;li&gt; ｛% for tag in site.tags %｝ ｛% assign blogPosts = site.posts | where: &apos;categories&apos;, category[0] | where: &apos;tags&apos;, tag[0]%｝ // 这里使用 where filter 来找到属于当前category下的 属于tag[0] 的所有文章。 ｛% if blogPosts.size != 0 %｝ ｛｛ tag[0] ｝｝ ｛｛ blogPosts.size｝｝ ｛% endif %｝ ｛% endfor %｝ &lt;/li&gt; &lt;/ul&gt;｛% endfor %｝ 最后生成的效果如图： 一些问题jekyll 生成文章过慢在某天的某刻，突然发现进行一次微小的post文章修改，jekyll serve –watch 命令下，regeneration 需要耗费 20s 多，以往都是 1-2s 就结束了。反复定位，发现是文章的 title 中写了一个 “C++”，而将其改为 “Cpp”以后就好了。虽然不知道为什么，但是问题还是解决了。猜测也许是因为 + 被jekyll 解析时候出了问题。 参考Categories in Jekyll]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>前端开发</tag>
        <tag>查阅</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Cpp Style Guide - Naming]]></title>
    <url>%2F2017%2F03%2F28%2F2017-03-28-Google-Cpp-Style-Guide-Naming%2F</url>
    <content type="text"><![CDATA[通用命名规则函数命名，变量命名，文件命名要有描述性；少用缩写。 尽可能给有描述性的命名，别心疼空间，毕竟让代码易于新读者理解很重要。不要用只有项目开发者能理解的缩写，也不要通过砍掉几个字母来缩写单词 123int price_count_reader; // 无缩写int num_errors; // “num” 本来就很常见int num_dns_connections; // 人人都知道 “DNS” 是啥 不要像下面这样写： 123456int n; // 莫名其妙。int nerr; // 怪缩写。int n_comp_conns; // 怪缩写。int wgc_connections; // 只有贵团队知道是啥意思。int pc_reader; // "pc" 有太多可能的解释了。int cstmr_id; // 有删减若干字母。 文件命名文件名要全部小写, 可以包含下划线 (_) 或连字符 (-). 按项目约定来. 如果并没有项目约定，”_” 更好。 可接受的文件命名: 1234* my_useful_class.cc* my-useful-class.cc* myusefulclass.cc* muusefulclass_test.cc // ``_unittest`` 和 ``_regtest`` 已弃用。 C++ 文件要以 .cc 结尾, 头文件以 .h 结尾. 专门插入文本的文件则以 .inc 结尾，参见 1.1. Self-contained 头文件。 不要使用已经存在于 /usr/include 下的文件名 (Yang.Y 注: 即编译器搜索系统头文件的路径), 如 db.h. 通常应尽量让文件名更加明确. http_server_logs.h 就比 logs.h 要好. 定义类时文件名一般成对出现, 如 foo_bar.h 和 foo_bar.cc, 对应于类 FooBar. 内联函数必须放在 .h 文件中. 如果内联函数比较短, 就直接放在 .h 中. 类型命名类型名称的每个单词首字母均大写, 不包含下划线: MyExcitingClass, MyExcitingEnum. 所有类型命名 —— 类, 结构体, 类型定义 (typedef), 枚举 —— 均使用相同约定. 例如: 变量命名变量名一律小写, 单词之间用下划线连接. 类的成员变量以下划线结尾, 但结构体的就不用，如:: a_local_variable, a_struct_data_member, a_class_data_member_. 普通变量命名:12string table_name; // 可 - 用下划线。string tablename; // 可 - 全小写。 但是不要这样写：1string tableName; // 差 - 混合大小写。 类数据成员： 不管是静态的还是非静态的，类数据成员都可以和普通变量一样, 但要接下划线。 1234567class TableInfo &#123; ... private: string table_name_; // 可 - 尾后加下划线。 string tablename_; // 可。 static Pool&lt;TableInfo&gt;* pool_; // 可。&#125;; 结构体变量:不管是静态的还是非静态的，结构体数据成员都可以和普通变量一样, 不用像类那样接下划线: 1234struct UrlTableProperties &#123; string name; int num_entries;&#125; 结构体与类的讨论参考 结构体 vs. 类 一节. 全局变量: 对全局变量没有特别要求, 少用就好, 但如果你要用, 可以用 g_ 或其它标志作为前缀, 以便更好的区分局部变量. 常量命名在全局或类里的常量名称前加 k: kDaysInAWeek. 且除去开头的 k 之外每个单词开头字母均大写。 所有编译时常量, 无论是局部的, 全局的还是类中的, 和其他变量稍微区别一下. k 后接大写字母开头的单词: 1const int kDaysInAWeek = 7; 这规则适用于编译时的局部作用域常量，不过要按变量规则来命名也可以。 函数命名常规函数使用大小写混合, 取值和设值函数则要求与变量名匹配: MyExcitingFunction(), MyExcitingMethod(), my_exciting_member_variable(), set_my_exciting_member_variable(). 常规函数: 函数名的每个单词首字母大写, 没有下划线。 如果您的某函数出错时就要直接 crash, 那么就在函数名加上 OrDie. 但这函数本身必须集成在产品代码里，且平时也可能会出错。 123AddTableEntry()DeleteUrl()OpenFileOrDie() 取值和设值函数: 取值（Accessors）和设值（Mutators）函数要与存取的变量名匹配. 这儿摘录一个类, num_entries_ 是该类的实例变量: 123456789class MyClass &#123; public: ... int num_entries() const &#123; return num_entries_; &#125; void set_num_entries(int num_entries) &#123; num_entries_ = num_entries; &#125; private: int num_entries_;&#125;; 其它非常短小的内联函数名也可以用小写字母, 例如. 如果你在循环中调用这样的函数甚至都不用缓存其返回值, 小写命名就可以接受. 名字空间命名名字空间用小写字母命名, 并基于项目名称和目录结构: google_awesome_project. 关于名字空间的讨论和如何命名, 参考 名字空间 一节. 枚举命名枚举的命名应当和 常量 或 宏 一致: kEnumName 或是 ENUM_NAME. 单独的枚举值应该优先采用 常量 的命名方式. 但 宏 方式的命名也可以接受. 枚举名 UrlTableErrors (以及 AlternateUrlTableErrors) 是类型, 所以要用大小写混合的方式. 12345678910enum UrlTableErrors &#123; kOK = 0, kErrorOutOfMemory, kErrorMalformedInput,&#125;;enum AlternateUrlTableErrors &#123; OK = 0, OUT_OF_MEMORY = 1, MALFORMED_INPUT = 2,&#125;; 2009 年 1 月之前, 我们一直建议采用 宏 的方式命名枚举值. 由于枚举值和宏之间的命名冲突, 直接导致了很多问题. 由此, 这里改为优先选择常量风格的命名方式. 新代码应该尽可能优先使用常量风格. 但是老代码没必要切换到常量风格, 除非宏风格确实会产生编译期问题. 宏命名你并不打算 使用宏, 对吧? 如果你一定要用, 像这样命名: MY_MACRO_THAT_SCARES_SMALL_CHILDREN. 参考 预处理宏; 通常 不应该 使用宏. 如果不得不用, 其命名像枚举命名一样全部大写, 使用下划线: 12#define ROUND(x) ...#define PI_ROUNDED 3.0 参考 Banner图转自一张图总结Google C++编程规范 转载自Google开源风格项目指南 英文原文:Google C++ Style Guide]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>查阅</tag>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown基本语法]]></title>
    <url>%2F2017%2F03%2F26%2F2017-03-26-markdown-syntax%2F</url>
    <content type="text"><![CDATA[概述转载于: Markdown 语法说明 (简体中文版) 宗旨Markdown 的目标是实现「易读易写」。 可读性，无论如何，都是最重要的。一份使用 Markdown 格式撰写的文件应该可以直接以纯文本发布，并且看起来不会像是由许多标签或是格式指令所构成。Markdown 语法受到一些既有 text-to-HTML 格式的影响，包括 Setext、atx、Textile、reStructuredText、Grutatext 和 EtText，而最大灵感来源其实是纯文本电子邮件的格式。 总之， Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像*强调*。Markdown 的列表看起来，嗯，就是列表。Markdown 的区块引用看起来就真的像是引用一段文字，就像你曾在电子邮件中见过的那样。 兼容 HTMLMarkdown 语法的目标是：成为一种适用于网络的书写语言。 Markdown 不是想要取代 HTML，甚至也没有要和它相近，它的语法种类很少，只对应 HTML 标记的一小部分。Markdown 的构想不是要使得 HTML 文档更容易书写。在我看来， HTML 已经很容易写了。Markdown 的理念是，能让文档更容易读、写和随意改。HTML 是一种发布的格式，Markdown 是一种书写的格式。就这样，Markdown 的格式语法只涵盖纯文本可以涵盖的范围。 不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。不需要额外标注这是 HTML 或是 Markdown；只要直接加标签就可以了。 要制约的只有一些 HTML 区块元素――比如 &lt;div&gt;、&lt;table&gt;、&lt;pre&gt;、&lt;p&gt; 等标签，必须在前后加上空行与其它内容区隔开，还要求它们的开始标签与结尾标签不能用制表符或空格来缩进。Markdown 的生成器有足够智能，不会在 HTML 区块标签外加上不必要的 &lt;p&gt; 标签。 例子如下，在 Markdown 文件里加上一段 HTML 表格：123456789这是一个普通段落。&lt;table&gt; &lt;tr&gt; &lt;td&gt;Foo&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;这是另一个普通段落。 请注意，在 HTML 区块标签间的 Markdown 格式语法将不会被处理。比如，你在 HTML 区块内使用 Markdown 样式的*强调*会没有效果。 HTML 的区段（行内）标签如 &lt;span&gt;、&lt;cite&gt;、&lt;del&gt; 可以在 Markdown 的段落、列表或是标题里随意使用。依照个人习惯，甚至可以不用 Markdown 格式，而直接采用 HTML 标签来格式化。举例说明：如果比较喜欢 HTML 的 &lt;a&gt; 或 &lt;img&gt; 标签，可以直接使用这些标签，而不用 Markdown 提供的链接或是图像标签语法。 和处在 HTML 区块标签间不同，Markdown 语法在 HTML 区段标签间是有效的。 特殊字符自动转换在 HTML 文件中，有两个字符需要特殊处理： &lt; 和 &amp; 。 &lt; 符号用于起始标签，&amp; 符号则用于标记 HTML 实体，如果你只是想要显示这些字符的原型，你必须要使用实体的形式，像是 &amp;lt; 和 &amp;amp;。 &amp; 字符尤其让网络文档编写者受折磨，如果你要打「AT&amp;T」 ，你必须要写成「AT&amp;amp;T」。而网址中的 &amp; 字符也要转换。比如你要链接到： http://images.google.com/images?num=30&amp;q=larry+bird 你必须要把网址转换写为： http://images.google.com/images?num=30&amp;amp;q=larry+bird 才能放到链接标签的 href 属性里。不用说也知道这很容易忽略，这也可能是 HTML 标准检验所检查到的错误中，数量最多的。 Markdown 让你可以自然地书写字符，需要转换的由它来处理好了。如果你使用的 &amp; 字符是 HTML 字符实体的一部分，它会保留原状，否则它会被转换成 &amp;amp;。 所以你如果要在文档中插入一个版权符号 ©，你可以这样写： &amp;copy; Markdown 会保留它不动。而若你写： AT&amp;T Markdown 就会将它转为： AT&amp;amp;T 类似的状况也会发生在 &lt; 符号上，因为 Markdown 允许 兼容 HTML ，如果你是把 &lt; 符号作为 HTML 标签的定界符使用，那 Markdown 也不会对它做任何转换，但是如果你写： 4 &lt; 5 Markdown 将会把它转换为： 4 &amp;lt; 5 不过需要注意的是，code 范围内，不论是行内还是区块， &lt; 和 &amp; 两个符号都一定会被转换成 HTML 实体，这项特性让你可以很容易地用 Markdown 写 HTML code （和 HTML 相对而言， HTML 语法中，你要把所有的 &lt; 和 &amp; 都转换为 HTML 实体，才能在 HTML 文件里面写出 HTML code。） 区块元素段落和换行一个 Markdown 段落是由一个或多个连续的文本行组成，它的前后要有一个以上的空行（空行的定义是显示上看起来像是空的，便会被视为空行。比方说，若某一行只包含空格和制表符，则该行也会被视为空行）。普通段落不该用空格或制表符来缩进。 「由一个或多个连续的文本行组成」这句话其实暗示了 Markdown 允许段落内的强迫换行（插入换行符），这个特性和其他大部分的 text-to-HTML 格式不一样（包括 Movable Type 的「Convert Line Breaks」选项），其它的格式会把每个换行符都转成 &lt;br /&gt; 标签。 如果你确实想要依赖 Markdown 来插入 &lt;br /&gt; 标签的话，在插入处先按入两个以上的空格然后回车。 的确，需要多费点事（多加空格）来产生 &lt;br /&gt; ，但是简单地「每个换行都转换为 &lt;br /&gt;」的方法在 Markdown 中并不适合， Markdown 中 email 式的 区块引用 和多段落的 列表 在使用换行来排版的时候，不但更好用，还更方便阅读。 标题Markdown 支持两种标题的语法，类 Setext 和类 atx 形式。 类 Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如： This is an H1 ============= This is an H2 ------------- 任何数量的 = 和 - 都可以有效果。 类 Atx 形式则是在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶，例如： # 这是 H1 ## 这是 H2 ###### 这是 H6 你可以选择性地「闭合」类 atx 样式的标题，这纯粹只是美观用的，若是觉得这样看起来比较舒适，你就可以在行尾加上 #，而行尾的 # 数量也不用和开头一样（行首的井字符数量决定标题的阶数）： # 这是 H1 # ## 这是 H2 ## ### 这是 H3 ###### 区块引用Markdown 标记区块引用是使用类似 email 中用 &gt; 的引用方式。如果你还熟悉在 email 信件中的引言部分，你就知道怎么在 Markdown 文件中建立一个区块引用，那会看起来像是你自己先断好行，然后在每行的最前面加上 &gt; ： &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, &gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. &gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. &gt; &gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse &gt; id sem consectetuer libero luctus adipiscing. Markdown 也允许你偷懒只在整个段落的第一行最前面加上 &gt; ： &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. &gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ： &gt; This is the first level of quoting. &gt; &gt; &gt; This is nested blockquote. &gt; &gt; Back to the first level. 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： &gt; ## 这是一个标题。 &gt; &gt; 1. 这是第一行列表项。 &gt; 2. 这是第二行列表项。 &gt; &gt; 给出一些例子代码： &gt; &gt; return shell_exec(&quot;echo $input | $markdown_script&quot;); 任何像样的文本编辑器都能轻松地建立 email 型的引用。例如在 BBEdit 中，你可以选取文字后然后从选单中选择增加引用阶层。 列表Markdown 支持有序列表和无序列表。 无序列表使用星号、加号或是减号作为列表标记： * Red * Green * Blue 等同于： + Red + Green + Blue 也等同于： - Red - Green - Blue 有序列表则使用数字接着一个英文句点： 1. Bird 2. McHale 3. Parish 很重要的一点是，你在列表标记上使用的数字并不会影响输出的 HTML 结果，上面的列表所产生的 HTML 标记为： &lt;ol&gt; &lt;li&gt;Bird&lt;/li&gt; &lt;li&gt;McHale&lt;/li&gt; &lt;li&gt;Parish&lt;/li&gt; &lt;/ol&gt; 如果你的列表标记写成： 1. Bird 1. McHale 1. Parish 或甚至是： 3. Bird 1. McHale 8. Parish 你都会得到完全相同的 HTML 输出。重点在于，你可以让 Markdown 文件的列表数字和输出的结果相同，或是你懒一点，你可以完全不用在意数字的正确性。 如果你使用懒惰的写法，建议第一个项目最好还是从 1. 开始，因为 Markdown 未来可能会支持有序列表的 start 属性。 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。 要让列表看起来更漂亮，你可以把内容用固定的缩进整理好： * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 但是如果你懒，那也行： * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 如果列表项目间用空行分开，在输出 HTML 时 Markdown 就会将项目内容用 &lt;p&gt;标签包起来，举例来说： * Bird * Magic 会被转换为： &lt;ul&gt; &lt;li&gt;Bird&lt;/li&gt; &lt;li&gt;Magic&lt;/li&gt; &lt;/ul&gt; 但是这个： * Bird * Magic 会被转换为： &lt;ul&gt; &lt;li&gt;&lt;p&gt;Bird&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Magic&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; 列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符： 1. This is a list item with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. 2. Suspendisse id sem consectetuer libero luctus adipiscing. 如果你每行都有缩进，看起来会看好很多，当然，再次地，如果你很懒惰，Markdown 也允许： * This is a list item with two paragraphs. This is the second paragraph in the list item. You&apos;re only required to indent the first line. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. * Another item in the same list. 如果要在列表项目内放进引用，那 &gt; 就需要缩进： * A list item with a blockquote: &gt; This is a blockquote &gt; inside a list item. 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： * 一列表项包含一个列表区块： &lt;代码写在这&gt; 当然，项目列表很可能会不小心产生，像是下面这样的写法： 1986. What a great season. 换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠。 1986\. What a great season. 代码区块和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 &lt;pre&gt; 和 &lt;code&gt; 标签来把代码区块包起来。 要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以，例如，下面的输入： 这是一个普通段落： 这是一个代码区块。 Markdown 会转换成： &lt;p&gt;这是一个普通段落：&lt;/p&gt; &lt;pre&gt;&lt;code&gt;这是一个代码区块。 &lt;/code&gt;&lt;/pre&gt; 这个每行一阶的缩进（4 个空格或是 1 个制表符），都会被移除，例如： Here is an example of AppleScript: tell application &quot;Foo&quot; beep end tell 会被转换为： &lt;p&gt;Here is an example of AppleScript:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;tell application &quot;Foo&quot; beep end tell &lt;/code&gt;&lt;/pre&gt; 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 在代码区块里面， &amp; 、 &lt; 和 &gt; 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，再加上缩进就可以了，剩下的 Markdown 都会帮你处理，例如： &lt;div class=&quot;footer&quot;&gt; &amp;copy; 2004 Foo Corporation &lt;/div&gt; 会被转换为： &lt;pre&gt;&lt;code&gt;&amp;lt;div class=&quot;footer&quot;&amp;gt; &amp;amp;copy; 2004 Foo Corporation &amp;lt;/div&amp;gt; &lt;/code&gt;&lt;/pre&gt; 代码区块中，一般的 Markdown 语法不会被转换，像是星号便只是星号，这表示你可以很容易地以 Markdown 语法撰写 Markdown 语法相关的文件。 分隔线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： * * * *** ***** - - - --------------------------------------- 区段元素链接Markdown 支持两种形式的链接语法： 行内式和参考式两种形式。 不管是哪一种，链接文字都是用 [方括号] 来标记。 要建立一个行内式的链接，只要在方块括号后面紧接着圆括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号把 title 文字包起来即可，例如： This is [an example](http://example.com/ &quot;Title&quot;) inline link. [This link](http://example.net/) has no title attribute. 会产生： &lt;p&gt;This is &lt;a href=&quot;http://example.com/&quot; title=&quot;Title&quot;&gt; an example&lt;/a&gt; inline link.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://example.net/&quot;&gt;This link&lt;/a&gt; has no title attribute.&lt;/p&gt; 如果你是要链接到同样主机的资源，你可以使用相对路径： See my [About](/about/) page for details. 参考式的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记： This is [an example][id] reference-style link. 你也可以选择性地在两个方括号中间加上一个空格： This is [an example] [id] reference-style link. 接着，在文件的任意处，你可以把这个标记的链接内容定义出来： [id]: http://example.com/ &quot;Optional Title Here&quot; 链接内容定义的形式为： 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字 接着一个冒号 接着一个以上的空格或制表符 接着链接的网址 选择性地接着 title 内容，可以用单引号、双引号或是括弧包着 下面这三种链接的定义都是相同： [foo]: http://example.com/ &quot;Optional Title Here&quot; [foo]: http://example.com/ &apos;Optional Title Here&apos; [foo]: http://example.com/ (Optional Title Here) 请注意：有一个已知的问题是 Markdown.pl 1.0.1 会忽略单引号包起来的链接 title。 链接网址也可以用尖括号包起来： [id]: &lt;http://example.com/&gt; &quot;Optional Title Here&quot; 你也可以把 title 属性放到下一行，也可以加一些缩进，若网址太长的话，这样会比较好看： [id]: http://example.com/longish/path/to/resource/here &quot;Optional Title Here&quot; 网址定义只有在产生链接的时候用到，并不会直接出现在文件之中。 链接辨别标签可以有字母、数字、空白和标点符号，但是并不区分大小写，因此下面两个链接是一样的： [link text][a] [link text][A] 隐式链接标记功能让你可以省略指定链接标记，这种情形下，链接标记会视为等同于链接文字，要用隐式链接标记只要在链接文字后面加上一个空的方括号，如果你要让 “Google” 链接到 google.com，你可以简化成： [Google][] 然后定义链接内容： [Google]: http://google.com/ 由于链接文字可能包含空白，所以这种简化型的标记内也许包含多个单词： Visit [Daring Fireball][] for more information. 然后接着定义链接： [Daring Fireball]: http://daringfireball.net/ 链接的定义可以放在文件中的任何一个地方，我比较偏好直接放在链接出现段落的后面，你也可以把它放在文件最后面，就像是注解一样。 下面是一个参考式链接的范例： I get 10 times more traffic from [Google] [1] than from [Yahoo] [2] or [MSN] [3]. [1]: http://google.com/ &quot;Google&quot; [2]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [3]: http://search.msn.com/ &quot;MSN Search&quot; 如果改成用链接名称的方式写： I get 10 times more traffic from [Google][] than from [Yahoo][] or [MSN][]. [google]: http://google.com/ &quot;Google&quot; [yahoo]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [msn]: http://search.msn.com/ &quot;MSN Search&quot; 上面两种写法都会产生下面的 HTML。 &lt;p&gt;I get 10 times more traffic from &lt;a href=&quot;http://google.com/&quot; title=&quot;Google&quot;&gt;Google&lt;/a&gt; than from &lt;a href=&quot;http://search.yahoo.com/&quot; title=&quot;Yahoo Search&quot;&gt;Yahoo&lt;/a&gt; or &lt;a href=&quot;http://search.msn.com/&quot; title=&quot;MSN Search&quot;&gt;MSN&lt;/a&gt;.&lt;/p&gt; 下面是用行内式写的同样一段内容的 Markdown 文件，提供作为比较之用： I get 10 times more traffic from [Google](http://google.com/ &quot;Google&quot;) than from [Yahoo](http://search.yahoo.com/ &quot;Yahoo Search&quot;) or [MSN](http://search.msn.com/ &quot;MSN Search&quot;). 参考式的链接其实重点不在于它比较好写，而是它比较好读，比较一下上面的范例，使用参考式的文章本身只有 81 个字符，但是用行内形式的却会增加到 176 个字元，如果是用纯 HTML 格式来写，会有 234 个字元，在 HTML 格式中，标签比文本还要多。 使用 Markdown 的参考式链接，可以让文件更像是浏览器最后产生的结果，让你可以把一些标记相关的元数据移到段落文字之外，你就可以增加链接而不让文章的阅读感觉被打断。 强调Markdown 使用星号（*）和底线（_）作为标记强调字词的符号，被 * 或 _ 包围的字词会被转成用 &lt;em&gt; 标签包围，用两个 * 或 _ 包起来的话，则会被转成 &lt;strong&gt;，例如： *single asterisks* _single underscores_ **double asterisks** __double underscores__ 会转成： &lt;em&gt;single asterisks&lt;/em&gt; &lt;em&gt;single underscores&lt;/em&gt; &lt;strong&gt;double asterisks&lt;/strong&gt; &lt;strong&gt;double underscores&lt;/strong&gt; 你可以随便用你喜欢的样式，唯一的限制是，你用什么符号开启标签，就要用什么符号结束。 强调也可以直接插在文字中间： un*frigging*believable 但是如果你的 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 如果要在文字前后直接插入普通的星号或底线，你可以用反斜线： \*this text is surrounded by literal asterisks\* 代码如果要标记一小段行内代码，你可以用反引号把它包起来（` ），例如： Use the `printf()` function. 会产生： &lt;p&gt;Use the &lt;code&gt;printf()&lt;/code&gt; function.&lt;/p&gt; 如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段： ``There is a literal backtick (`) here.`` 这段语法会产生： &lt;p&gt;&lt;code&gt;There is a literal backtick (`) here.&lt;/code&gt;&lt;/p&gt; 代码区段的起始和结束端都可以放入一个空白，起始端后面一个，结束端前面一个，这样你就可以在区段的一开始就插入反引号： A single backtick in a code span: `` ` `` A backtick-delimited string in a code span: `` `foo` `` 会产生： &lt;p&gt;A single backtick in a code span: &lt;code&gt;`&lt;/code&gt;&lt;/p&gt; &lt;p&gt;A backtick-delimited string in a code span: &lt;code&gt;`foo`&lt;/code&gt;&lt;/p&gt; 在代码区段内，&amp; 和尖括号都会被自动地转成 HTML 实体，这使得插入 HTML 原始码变得很容易，Markdown 会把下面这段： Please don&apos;t use any `&lt;blink&gt;` tags. 转为： &lt;p&gt;Please don&apos;t use any &lt;code&gt;&amp;lt;blink&amp;gt;&lt;/code&gt; tags.&lt;/p&gt; 你也可以这样写： `&amp;#8212;` is the decimal-encoded equivalent of `&amp;mdash;`. 以产生： &lt;p&gt;&lt;code&gt;&amp;amp;#8212;&lt;/code&gt; is the decimal-encoded equivalent of &lt;code&gt;&amp;amp;mdash;&lt;/code&gt;.&lt;/p&gt; 图片很明显地，要在纯文字应用中设计一个「自然」的语法来插入图片是有一定难度的。 Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式： 行内式和参考式。 行内式的图片语法看起来像是： ![Alt text](/path/to/img.jpg) ![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 详细叙述如下： 一个惊叹号 ! 接着一个方括号，里面放上图片的替代文字 接着一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上选择性的 ‘title’ 文字。 参考式的图片语法则长得像这样： ![Alt text][id] 「id」是图片参考的名称，图片参考的定义方式则和连结参考一样： [id]: url/to/image &quot;Optional title attribute&quot; 到目前为止， Markdown 还没有办法指定图片的宽高，如果你需要的话，你可以使用普通的 &lt;img&gt; 标签。 其它自动链接Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用尖括号包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如： &lt;http://example.com/&gt; Markdown 会转为： &lt;a href=&quot;http://example.com/&quot;&gt;http://example.com/&lt;/a&gt; 邮址的自动链接也很类似，只是 Markdown 会先做一个编码转换的过程，把文字字符转成 16 进位码的 HTML 实体，这样的格式可以糊弄一些不好的邮址收集机器人，例如： &lt;address@example.com&gt; Markdown 会转成： &lt;a href=&quot;&amp;#x6D;&amp;#x61;i&amp;#x6C;&amp;#x74;&amp;#x6F;:&amp;#x61;&amp;#x64;&amp;#x64;&amp;#x72;&amp;#x65; &amp;#115;&amp;#115;&amp;#64;&amp;#101;&amp;#120;&amp;#x61;&amp;#109;&amp;#x70;&amp;#x6C;e&amp;#x2E;&amp;#99;&amp;#111; &amp;#109;&quot;&gt;&amp;#x61;&amp;#x64;&amp;#x64;&amp;#x72;&amp;#x65;&amp;#115;&amp;#115;&amp;#64;&amp;#101;&amp;#120;&amp;#x61; &amp;#109;&amp;#x70;&amp;#x6C;e&amp;#x2E;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt; 在浏览器里面，这段字串（其实是 &lt;a href=&quot;mailto:address@example.com&quot;&gt;address@example.com&lt;/a&gt;）会变成一个可以点击的「address@example.com」链接。 （这种作法虽然可以糊弄不少的机器人，但并不能全部挡下来，不过总比什么都不做好些。不管怎样，公开你的信箱终究会引来广告信件的。） 反斜杠Markdown 可以利用反斜杠来插入一些在语法中有其它意义的符号，例如：如果你想要用星号加在文字旁边的方式来做出强调效果（但不用 &lt;em&gt; 标签），你可以在星号的前面加上反斜杠： \*literal asterisks\* Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号： \ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
        <tag>查阅</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10分钟入门requireJs]]></title>
    <url>%2F2017%2F03%2F25%2F2017-03-25-how-to-use-requirejs%2F</url>
    <content type="text"><![CDATA[目录{:toc } 引入 下载 requireJs，然后在 head 中 1&lt;script src="js/require.js" data-main="js/main" defer async="true"&gt;&lt;/script&gt; async 属性表明这个文件需要异步加载，避免网页失去响应。IE不支持这个属性，只支持 defer，所以把 defer 也写上。 data-main 属性的作用是，指定网页程序的主模块。在上例中，就是js目录下面的 main.js，这个文件会第一个被 require.js 加载。由于require.js 默认的文件后缀名是js，所以可以把 main.js 简写成 main。 基本API require 会定义三个变量：define, require, requirejs，其中 require === requirejs，一般使用 require 更简短 define 从名字就可以看出这个api是用来定义一个模块 require 加载依赖模块，并执行加载完后的回调函数 比如我们想写一个 a.js 的模块，实现一个功能： 1234567define(function()&#123; function fun1()&#123; alert("it works"); &#125; fun1();&#125;) 这里通过 define 函数定义了一个模块，这是 requirejs 的标准写法。如果想在页面中使用该 js ，可以直接在 html 文件中调用： 1require(["js/a"]); 如果我们的网页目录如下： 并且 index.html 内容如下，通过主动 require 的方式调用 a.js： 12345678910111213&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;script type="text/javascript" src="js/lib/require.js"&gt;&lt;/script&gt; &lt;!-- 这里只是主动加载了a.js，并没有定义加载结束后的回调函数，其功能即为只执行a.js中代码 --&gt; &lt;script type="text/javascript"&gt; require(["js/a"]); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;span&gt;body&lt;/span&gt; &lt;/body&gt;&lt;/html&gt; 这时候网页就会弹出一个alert 对话框： 如果将 index.html 写成如下： 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;script type="text/javascript" src="js/lib/require.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; require(["js/a"], function()&#123; alert("call back!"); &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;span&gt;body&lt;/span&gt; &lt;/body&gt;&lt;/html&gt; 那么会在 ‘It works’ 后，再弹出一个对话框： 加载文件和全局配置也许你会说，这样调用的方式，如果我有 a,b,c,d… 等 js 代码，不还是得一个个写到 head 里的 &lt;script&gt; 标签内调用么。不急，下面才是重点。 首先我们在 js 目录下新建一个 main.js： 然后在 main.js 中写如下代码： 123456789require.config(&#123; paths : &#123; "a" : "js/a" &#125;&#125;)require(['a'],function()&#123;alert('finish load');&#125;); 然后在 index.html 中这样写： 123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;script type="text/javascript" src="js/lib/require.js" &gt;&lt;/script&gt; &lt;script&gt; require(['js/main']); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;span&gt;body&lt;/span&gt; &lt;/body&gt;&lt;/html&gt; 这里用到了 require.config。require.config 是用来配置模块加载位置的。即给我们的 js 模块，取一个 别名，之后进行 require 的时候，就不用以输入路径的方式来调用，直接写这个 别名 就行。 可以看到上面代码写 require 的时候，直接是使用 require([&#39;a&#39;] 而不是之前的 require([&quot;js/a&quot;]。 这样如果我们有很多的代码，就可以在 main.js 中，先配置各个模块的路径，并起别名，然后挨个 require 调用就是了。就不用对 head 标签进行修改。 同时如果我们在 index.html 中这样写： 1&lt;script type="text/javascript" src="js/lib/require.js" data-main="js/main" defer async="true"&gt;&lt;/script&gt; 这里 data-main 属性的作用是，指定网页程序的主模块。在上例中，就是js目录下面的 main.js，这个文件会自动被 require.js 加载。这样我们就只用写一个 &lt;script&gt; 标签，就实现了对所有的 js 模块的调用。 data-main 还有一个重要的功能：当 script 标签指定 data-main 属性时，require 会默认的将 data-main 指定的 js 为根路径。即之后如果写 require 来调用 js 模块，不需要再添加 ‘js’ 目录前缀。 async 属性表明这个文件需要异步加载，避免网页失去响应。IE不支持这个属性，只支持 defer，所以把 defer 也写上。 下面是使用 data-main 属性时候的 html 和 js 文件写法： 123456789&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;script type="text/javascript" src="js/lib/require.js" data-main="js/main" defer async="true"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;span&gt;body&lt;/span&gt; &lt;/body&gt;&lt;/html&gt; 12345678910require.config(&#123; //这里看到指定 a.js 模块路径的时候，并没有写上其路径前缀 'js/'，这就是 data-main 属性的作用 paths : &#123; "a_alias" : "a" &#125;&#125;)require(['a_alias'],function()&#123;alert('finish load');&#125;); 加载不符合AMD规范模块 标准的写法是需要使用一个：123define(function()&#123; // your code here&#125;); 将你的代码写在这个 define 内部。但是我们如果想要使用一个不是这种标准的 js 模块怎么破？ 这里就要使用到 shim。我们看下面的完整配置 main.js ：12345678910111213141516171819202122232425262728requirejs.config(&#123; paths: &#123; jquery: [ 'lib/jquery.min' ], bootstrap: [ '//cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min', // 这里支持输入多个备选路径，前一个失败就是选择下一个 'lib/bootstrap.min' ], my:'my' &#125;, shim:&#123; 'bootstrap':&#123; deps:['jquery'] // 这里指定依赖关系，bootstrap 要在 jquery 加载完成之后再加载 &#125;, 'my':&#123; deps:['jquery','bootstrap'], exports:'my_alis' &#125; &#125; &#125;); require([ 'jquery','bootstrap','my' ], function($, my_alis)&#123; // my 中的变量和函数，只在这里有效。 &#125;); 这里假设我使用了 jquery 和 bootstrap 模块，还有一个自己写的业务脚本 my.js。 my.js 因为要依赖于 jquery 和 bootstrap 所以在依赖关系中写了上面的配置。 关键在于 export 关键字的声明。这样我们就可以加载一个没有使用 AMD 规范编程的 js 模块了。并且模块的所有变量，和函数，都不是在全局域的，只在 回调函数中有效。从而避免了全局变量的污染问题。 参考： JS模块化工具requirejs教程(二)：基本知识 Javascript模块化编程（三）：require.js的用法]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>前端开发</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
</search>
